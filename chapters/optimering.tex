\section{Prestandaoptimering}

Beskriv varför JavaScript behöver micro optimering.

\subsection{Insamling av data}

Beskriv processen för test samt sample standard deviation.

\subsection{Analysering av data för V8}

Beskriv varför v8.

\subsubsection{Provatgning}

Beskriv provtagningsverktyget och hur datat läses.

\begin{figure}[ht]
  \includegraphics[width=13cm]{figures/output/functions.pdf}
  \caption{Översikt av de mest prestandakrävande funktionerna.}
\end{figure}

\subsection{Optimeringstekniker för V8}

Javascript-motorn V8 innehåller en optimeringskompilator kallad Crankshaft,
vars syfte är att identifiera kod som körs mycket för att sedan spendera sin
tid på att optimera den istället för mindre väsentliga funktioner. Detta
fungerar så att baskompilatorn börjar med att kompilera koden varefter en
s.k. \textit{``runtime-profiler''} övervakar körningen av programmet och
identifierar den kod som körs aktivt. När de väsentliga programdelarna är
identifierade optimeras och omkompileras de ivrigt av optimeringskompilatorn.
Innebörden med att kod omkompileras ivrigt är att kompilatorn inte kan vara
säker på att optimeringen är möjlig att genomföra men försöker i alla fall. Om
det visar sig att optimeringen inte var möjlig, finns det ytterligare en
komponent i V8 som kan återgå till baskompilatorns ursprungliga version
\citep{mk10}. Denna åtgärd kallas för avoptimering och inträffar aktivt i
körningen av javascript eftersom språket är dynamiskt och en avoptimering sker
varje gång en datatyp konverteras. Ytterligare existerar det vissa specifika
strukturer som kompilatorn inte kan optimera, exempelvis try/catch-satser och
vissa typer av switch-satser. Även här görs en avoptimering men den kallas
nu för en s.k. bailout.

V8 och därmed även Node.JS har diverse kommandoradsflaggor som hjälper att
identifiera funktioner var detta sker samt ger information om varför det sker.

\subsubsection{Undvikande av bailouts}

Trots att bailouts möjliggör en allmän prestandaförbättring hos
V8 är det klokt att undvika avoptimeringen eftersom den kostar en del
prestanda och kommer att återupprepas vid varje exekvering.

Kommandoradsflaggan \textit{--trace_bailout} matar ut en lista på funktioner
samt orsaken till varför en bailout gjorts. Genom att exekvera en parsning med
flaggan aktiverad går det att identifiera två funktioner som gör en bailout,
bägge på grund av ooptimerbara switch-satser där en icke-litteral label har
används.

Funktionerna som har orsakat dessa bailouts är \textit{isUnary()} samt
\textit{parsePrimaryExpression()} som bägge består av en switch-sats som utför
olika operationer beroende på om en given token är lika med ett visst
variabelvärde.  Detta är ett enkelt problem att lösa eftersom bailouten inte
sker för ``if-sats''-motsvarigheten och därmed kan koden optimeras enligt
\nobreak{figur~\ref{fig:bailout}}.

\lstloadlanguages{JavaScript}
\begin{figure}[ht]
  \begin{minipage}[t]{0.5\textwidth}
    \lstinputlisting[title=a) Funktion före,language=Javascript]%
      {figures/tex/bailout-pre.js}
  \end{minipage}%
  \begin{minipage}[t]{0.5\textwidth}
    \lstinputlisting[title=b) Funktion efter,language=Javascript]%
      {figures/tex/bailout-post.js}
  \end{minipage}
  \caption{Förändring av funktionen isUnary från icke-optimerbar till
  optimerbar.}
  \label{fig:bailout}
\end{figure}

\subsubsection{Function inlining}

Crankshaft använder sig även av optimeringstekniken
\textit{``function inlining''}. Detta innebär att kompilatorn ersätter ett
funktionsanrop med själva funktionsinnehållet och sparar därmed kostnaden av
själva funktionsanropet och dess returnering. Dessutom möjliggörs ytterligare
optimeringsmöjligheter eftersom koden nu är mer kompakt och introducerar
satser som möjligen kan kombineras med omliggande kod.

V8 har dock vissa begränsningar för vilka funktioner som lämpar sig för
\textit{``function inlining''}.  Bland annat får källkoden inte överstiga 600
byte och funktioner kan inte heller innehålla en array som definierats med den
litterala syntaxen istället för med konstruktorn. I V8-motorn som kommer med
Node.JS v0.8 fungerar inte \textit{``function inlining''} hos objekt som
skapats med den litterala syntaxen.

% @TODO add v8 references

Lexer-implementationen som gjorts använde till att börja med två separata
funktioner som skapade och avslutade token-noder. Eftersom noderna var
uppgjorda av objekt kunde dessa inte \textit{``function inlining''} inte
utnyttjas och därmed introducerades ett extra funktionsanrop för varje token
som hittades under en parsning. På grund av jag inte ansåg detta påverka
läsligheten eller komplexiteten av koden ansåg jag det vara värt att expandera
skapandet och avslutandet av noderna i varje enskild token-funktion.

\subsubsection{Teckenkoder istället för reguljära uttryck}

Med användning av provtagningsverktyget i V8 är det möjligt att få en överblick
i vilka funktioner och operationer som är mest aktiva under en exekvering.
Genom att analysera detta resultat framgick att 39.2\% av en hel exekvering
går åt till reguljära uttryck som används för att identifiera blanksteg och
giltiga identifierare.

Eftersom dessa operationer ansvarade för en extremt stor del av
parsningsprocessen omvandlades de till binära operationer som jämför
teckenkoder istället. Orsaken till att teckenkoder används istället för sträng
litteraler är att en kompilator måste omvandla tecken till siffror för att göra
jämförelser. Denna operation visar sig ha en betydande prestanda skillnad i
äldre V8 versioner samt i övriga webbläsare.

% @TODO (hur ska dessa refereras? http://jsperf.com/charcodeat-vs-string-comparison/2).

\subsubsection{Optimering av sträng-funktioner}

Efter att de tidigare optimeringarna genomförts betonas nu 2 huvudsakliga
funktioner ut i provtagningsanalysen. Dessa funktioner, dvs.
\textit{StringAddStub} som är en maskinkodmetod för att sammanfoga strängar
och \textit{CompareICStub} som är en metod för att jämföra strängar upptar
8.3\% respektive 7.9\% av parsningsprocessens exekveringstid.

\textit{StringAddStub} orsakas av att lexern sammanfogar token-värden för
kommentarer, tal och identifierare genom att iterera över varje tecken så
länge som en avgränsare inte påträffas. Denna procedur går att försenkla genom
att istället räkna var värdet börjar och sedan iterera fram till avgränsaren
och i det skedet identifier värdet från dess startposition till avgränsarens
position enligt exemplet i figur~\ref{fig:stringAddStub}.

\lstloadlanguages{JavaScript}
\begin{figure}[ht]
  \begin{minipage}[t]{0.5\textwidth}
    \lstinputlisting[title=a) Procedur före,language=Javascript]%
      {figures/tex/stringaddstub-pre.js}
  \end{minipage}%
  \begin{minipage}[t]{0.5\textwidth}
    \lstinputlisting[title=b) Procedur efter,language=Javascript]%
      {figures/tex/stringaddstub-post.js}
  \end{minipage}
  \caption{Procedur förändring från strängsammanfogning till identifiering.}
  \label{fig:stringAddStub}
\end{figure}

% @TODO särskriva? @TODO vad ha göran skrivit @TODO träd
Vid vidare analys av provtagningsinformationen gick det att utläsa att den
huvudsakliga orsaken för den långsamma \textit{CompareICStub}-operationen var
en \textit{``function inlining''} i uttrycks parsern. Funktionen ansvarar för
att ange prioriteten av en given binär operator utgående från en switch-sats
med strängjämförelser. Eftersom funktionen körs för varje uttryck som hittas
valde jag att uppoffra läsligheten med att istället jämföra teckenkoder i
form av ett träd enligt figur~\ref{fig:switchtree}. Efter att optimeringen
gjorts validerade jag ännu att funktionen var tillräkligt liten för
\textit{``function inlining''}, vilket den visade sig vara.

\begin{figure}[ht]
  \lstinputlisting[title="",language=Javascript]%
    {figures/tex/prefixtree.js}
  \caption{Optimerad träd implementation av en vanlig switch-sats för
    strängar.} \label{fig:switchtree}
\end{figure}

\subsubsection{Skräpinsamling}

V8 består av två typer av skräpinsamlare som den väljer mellan att använda
under en exekvering. Den första är en s.k. scavanger som arbetar snabbt men enbart
på indirekt skapade objekt, dvs. objekt utan nyckelordet new. Den andra typen
använder sig av en s.k. mark-sweep algoritm som även granskar indirekt skapade
objekt men är betydligt långsammare \citep{ma10}.

Eftersom parsern implementerats med hjälp av s.k. scopes och funktioner istället
för med en objektorienterad paradigm är all allokering indirekt. Därmed finns
det ingen oro om att minne skall läcka så länge som mer avancerade closure
inte används. När en funktion körts färdigt blir alla variabler som
definierats inne i funktionen utom räckhåll för programmet och därmed kommer
de att tas bort vid nästa scavanger-runda. På grund av att minnet reserveras
med hjälp av scopes är det därför viktigt att undvika globala variabler
samt att se till att hela programmet är knytet till ett eget scope som utomstående
objekt inte har tillgång till.

Med hjälp av kommandoradsflagga \textit{--trace_gc} kan vi se vilken typ av
skräpinsamling som görs samt hur länge den pågått.

Utgående från resultatet ser vi att det sker 215 scavange-samlingar som alla
tar under 1ms att utföra, samt en mark-sweep som utförs tidigt i exekveringen
och kräver 7ms tid. Utgående från detta kan det konstateras att
implementationen inte läcker minne och att scavange-samlaren kan upprätthålla
programmet utan mer än en inledande mark-sweep.

% @TODO oförståeligt

\subsection{Resultat}

Beskriv vart vi kommit och varför vi inte kan optimera mer.

\begin{figure}[ht]
  \includegraphics[width=15cm]{figures/output/commits.pdf}
  \caption{Översikt av de mest prestandapåverkande kod commitsen}
\end{figure}

% vim: set tw=78:ts=2:sw=2:et:fdm=marker:wrap:wm=78:ft=tex
% vim: spell spelllang=sv
